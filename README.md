# Generador y Discriminador para Fashion MNIST con GAN ğŸ‘—ğŸ‘šğŸ‘Ÿ

Este proyecto implementa un modelo Generativo AntagÃ³nico (GAN) para generar imÃ¡genes de prendas de ropa y accesorios utilizando el conjunto de datos *Fashion MNIST*. El objetivo es entrenar un generador capaz de crear imÃ¡genes realistas a partir de ruido aleatorio, mientras que el discriminador aprende a distinguir entre imÃ¡genes reales y generadas. ğŸ¤–

## Requisitos ğŸ“¦
Para ejecutar este proyecto, necesitas tener las siguientes librerÃ­as instaladas:
- **Python 3.x**
- **TensorFlow 2.x**
- **NumPy**
- **Matplotlib**
- **PIL (Python Imaging Library)**
- **imageio**

Se pueden instalar estas dependencias con `pip install tensorflow numpy matplotlib pillow imageio`

## DescripciÃ³n del Modelo ğŸ“‹
El proyecto consiste en dos componentes principales:
1. **Generador** ğŸ¨: Este modelo toma un vector de ruido aleatorio y lo transforma en una imagen de 28x28 pÃ­xeles con una sola capa de canal (en escala de grises). A travÃ©s de un proceso de convoluciÃ³n transpuesta, el generador crea imÃ¡genes que imitan las prendas de ropa y accesorios en el conjunto de datos *Fashion MNIST*.
2. **Discriminador** ğŸ§: El discriminador es una red neuronal convolucional que clasifica las imÃ¡genes entre reales (provenientes del conjunto de datos) y falsas (producidas por el generador). Su tarea es aprender a identificar si una imagen es genuina o generada, proporcionando retroalimentaciÃ³n para mejorar el generador.

## Estructura del Modelo GAN
- **Generador**: Utiliza capas densas y convoluciÃ³n transpuesta para generar imÃ¡genes a partir de ruido aleatorio.
- **Discriminador**: Usa convoluciÃ³n para analizar las imÃ¡genes y una capa densa para clasificar las imÃ¡genes como reales o falsas.

## OptimizaciÃ³n âš™ï¸
Ambos modelos (generador y discriminador) se optimizan con el optimizador **Adam**, que es ampliamente utilizado por su eficiencia y capacidad para adaptarse a los gradientes de los modelos. La **entropÃ­a cruzada binaria** es la funciÃ³n de pÃ©rdida utilizada en este proyecto, ya que mide la diferencia entre las predicciones del discriminador y las etiquetas reales o falsas. Esto permite que tanto el generador como el discriminador aprendan de sus errores y mejoren en sus respectivas tareas:
- **Generador**: Su objetivo es engaÃ±ar al discriminador para que clasifique las imÃ¡genes generadas como reales.
- **Discriminador**: Su tarea es clasificar correctamente las imÃ¡genes reales y generadas, distinguiendo las imÃ¡genes verdaderas de las falsas.

## Entrenamiento ğŸš€
### ParÃ¡metros de Entrenamiento ğŸ”§
- **EPOCHS**: NÃºmero de Ã©pocas para entrenar el modelo.
- **LATENT_DIM**: DimensiÃ³n del vector de ruido utilizado como entrada del generador.
- **BATCH_SIZE**: NÃºmero de imÃ¡genes procesadas por lote durante el entrenamiento.

Durante el entrenamiento, el generador y el discriminador compiten en un juego de cero-suma. El discriminador intenta clasificar correctamente las imÃ¡genes reales y generadas, mientras que el generador intenta engaÃ±ar al discriminador creando imÃ¡genes que parezcan reales. Las pÃ©rdidas de ambos modelos se calculan usando *Binary Cross-Entropy*.

### Progreso del Entrenamiento ğŸ“ˆ
Al final de cada Ã©poca, se genera un conjunto de imÃ¡genes producidas por el generador, que se muestran para visualizar el progreso. El modelo guarda las imÃ¡genes generadas en cada Ã©poca y permite visualizar cÃ³mo mejoran con el tiempo.


## Uso del modelo
1. **Entrenar el modelo**: Para comenzar el entrenamiento, solo necesitas ejecutar la funciÃ³n `train()` con el conjunto de datos y la cantidad de Ã©pocas que deseas entrenar.
```python
train(train_dataset, EPOCHS)
```
2. **Ver las imÃ¡genes generadas**: DespuÃ©s de entrenar el modelo, puedes visualizar las imÃ¡genes generadas por el generador en la Ãºltima Ã©poca. Esto se hace mediante la funciÃ³n `display_image()`.
```python
display_image(EPOCHS - 1)
```
3. **Guardar el modelo** ğŸ’¾: Al final del entrenamiento, el generador y el discriminador se guardan en archivos `.keras` para su posterior uso o fine-tuning.

## Resultados ğŸ“¸
El entrenamiento puede tomar varias horas dependiendo de la capacidad de la GPU o TPU utilizada. Los resultados generados en cada Ã©poca son guardados en archivos de imagen, que se pueden visualizar durante y despuÃ©s del entrenamiento.

## Licencia ğŸ“œ
Este proyecto estÃ¡ bajo la Licencia MIT. Para mÃ¡s detalles, consulta el archivo `LICENSE`.


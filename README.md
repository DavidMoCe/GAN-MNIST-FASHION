# Generator and Discriminator for Fashion MNIST with GAN ğŸ‘—ğŸ‘šğŸ‘Ÿ

## ğŸŒ Chose Your Language / Elige tu idioma:
- [English](#english-gb)
- [EspaÃ±ol](#espaÃ±ol-es)

---

## English GB

This project implements a Generative Adversarial Network (GAN) model to generate images of clothing and accessories using the *Fashion MNIST* dataset. The goal is to train a generator capable of creating realistic images from random noise, while the discriminator learns to distinguish between real and generated images. ğŸ¤–

## Requirements ğŸ“¦
To run this project, you need to have the following libraries installed:
- **Python 3.x**
- **TensorFlow 2.x**
- **NumPy**
- **Matplotlib**
- **PIL (Python Imaging Library)**
- **imageio**

You can install these dependencies with `pip install tensorflow numpy matplotlib pillow imageio`.

## Model Description ğŸ“‹
The project consists of two main components:
1. **Generator** ğŸ¨: This model takes a random noise vector and transforms it into a 28x28 pixel image with a single channel (grayscale). Through a transposed convolution process, the generator creates images that mimic the clothing and accessories in the *Fashion MNIST* dataset.
2. **Discriminator** ğŸ§: The discriminator is a convolutional neural network that classifies images as real (from the dataset) or fake (generated by the generator). Its task is to learn to identify whether an image is genuine or generated, providing feedback to improve the generator.

## GAN Model Structure
- **Generator**: Uses dense layers and transposed convolution to generate images from random noise.
- **Discriminator**: Uses convolution to analyze images and a dense layer to classify the images as real or fake.

## Optimization âš™ï¸
Both models (generator and discriminator) are optimized using the **Adam** optimizer, which is widely used for its efficiency and adaptability to model gradients. **Binary cross-entropy** is the loss function used in this project, as it measures the difference between the discriminator's predictions and the real or fake labels. This allows both the generator and discriminator to learn from their mistakes and improve their respective tasks:
- **Generator**: Its goal is to fool the discriminator into classifying generated images as real.
- **Discriminator**: Its task is to correctly classify real and generated images, distinguishing true images from fake ones.

## Training ğŸš€
### Training Parameters ğŸ”§
- **EPOCHS**: Number of epochs to train the model.
- **LATENT_DIM**: Dimension of the noise vector used as input to the generator.
- **BATCH_SIZE**: Number of images processed per batch during training.

During training, the generator and discriminator compete in a zero-sum game. The discriminator tries to correctly classify real and generated images, while the generator tries to deceive the discriminator by creating images that look real. The losses of both models are calculated using *Binary Cross-Entropy*.

### Training Progress ğŸ“ˆ
At the end of each epoch, a set of images produced by the generator is generated and displayed to visualize the progress. The model saves the generated images at each epoch and allows you to see how they improve over time.


## Using the model
1. **Train the model**: To begin training, simply execute the `train()` function with the dataset and the number of epochs you want to train.
```python
train(train_dataset, EPOCHS)
```
2. **View generated images**: After training the model, you can view the images generated by the generator in the last epoch. This is done using the  `display_image()` function.
```python
display_image(EPOCHS - 1)
```
3. **Save the model** ğŸ’¾: At the end of training, the generator and discriminator are saved as `.keras` files for later use or fine-tuning.

## Results ğŸ“¸
Training may take several hours depending on the capacity of the GPU or TPU used. The results generated at each epoch are saved as image files, which can be viewed during and after training.

### Example of Generated Images ğŸ–¼ï¸

Below are two examples of images generated during the training of the GAN model:

1. **Image generated in Epoch 02**:  
   ![Image generated in Epoch 02](https://github.com/DavidMoCe/GAN-MNIST-FASHION/blob/main/image/start.png)

2. **Image generated in the last epoch:**:  
   ![Image generated in the last epoch](https://github.com/DavidMoCe/GAN-MNIST-FASHION/blob/main/image/end.png)


## License ğŸ“œ
This project is licensed under the **CC BY-NC 4.0** license. See the [`LICENSE`](https://github.com/DavidMoCe/GAN-MNIST-FASHION/blob/main/LICENSE.txt) file for more details.

---

## EspaÃ±ol ES

Este proyecto implementa un modelo Generativo AntagÃ³nico (GAN) para generar imÃ¡genes de prendas de ropa y accesorios utilizando el conjunto de datos *Fashion MNIST*. El objetivo es entrenar un generador capaz de crear imÃ¡genes realistas a partir de ruido aleatorio, mientras que el discriminador aprende a distinguir entre imÃ¡genes reales y generadas. ğŸ¤–

## Requisitos ğŸ“¦
Para ejecutar este proyecto, necesitas tener las siguientes librerÃ­as instaladas:
- **Python 3.x**
- **TensorFlow 2.x**
- **NumPy**
- **Matplotlib**
- **PIL (Python Imaging Library)**
- **imageio**

Se pueden instalar estas dependencias con `pip install tensorflow numpy matplotlib pillow imageio`

## DescripciÃ³n del Modelo ğŸ“‹
El proyecto consiste en dos componentes principales:
1. **Generador** ğŸ¨: Este modelo toma un vector de ruido aleatorio y lo transforma en una imagen de 28x28 pÃ­xeles con una sola capa de canal (en escala de grises). A travÃ©s de un proceso de convoluciÃ³n transpuesta, el generador crea imÃ¡genes que imitan las prendas de ropa y accesorios en el conjunto de datos *Fashion MNIST*.
2. **Discriminador** ğŸ§: El discriminador es una red neuronal convolucional que clasifica las imÃ¡genes entre reales (provenientes del conjunto de datos) y falsas (producidas por el generador). Su tarea es aprender a identificar si una imagen es genuina o generada, proporcionando retroalimentaciÃ³n para mejorar el generador.

## Estructura del Modelo GAN
- **Generador**: Utiliza capas densas y convoluciÃ³n transpuesta para generar imÃ¡genes a partir de ruido aleatorio.
- **Discriminador**: Usa convoluciÃ³n para analizar las imÃ¡genes y una capa densa para clasificar las imÃ¡genes como reales o falsas.

## OptimizaciÃ³n âš™ï¸
Ambos modelos (generador y discriminador) se optimizan con el optimizador **Adam**, que es ampliamente utilizado por su eficiencia y capacidad para adaptarse a los gradientes de los modelos. La **entropÃ­a cruzada binaria** es la funciÃ³n de pÃ©rdida utilizada en este proyecto, ya que mide la diferencia entre las predicciones del discriminador y las etiquetas reales o falsas. Esto permite que tanto el generador como el discriminador aprendan de sus errores y mejoren en sus respectivas tareas:
- **Generador**: Su objetivo es engaÃ±ar al discriminador para que clasifique las imÃ¡genes generadas como reales.
- **Discriminador**: Su tarea es clasificar correctamente las imÃ¡genes reales y generadas, distinguiendo las imÃ¡genes verdaderas de las falsas.

## Entrenamiento ğŸš€
### ParÃ¡metros de Entrenamiento ğŸ”§
- **EPOCHS**: NÃºmero de Ã©pocas para entrenar el modelo.
- **LATENT_DIM**: DimensiÃ³n del vector de ruido utilizado como entrada del generador.
- **BATCH_SIZE**: NÃºmero de imÃ¡genes procesadas por lote durante el entrenamiento.

Durante el entrenamiento, el generador y el discriminador compiten en un juego de cero-suma. El discriminador intenta clasificar correctamente las imÃ¡genes reales y generadas, mientras que el generador intenta engaÃ±ar al discriminador creando imÃ¡genes que parezcan reales. Las pÃ©rdidas de ambos modelos se calculan usando *Binary Cross-Entropy*.

### Progreso del Entrenamiento ğŸ“ˆ
Al final de cada Ã©poca, se genera un conjunto de imÃ¡genes producidas por el generador, que se muestran para visualizar el progreso. El modelo guarda las imÃ¡genes generadas en cada Ã©poca y permite visualizar cÃ³mo mejoran con el tiempo.


## Uso del modelo
1. **Entrenar el modelo**: Para comenzar el entrenamiento, solo necesitas ejecutar la funciÃ³n `train()` con el conjunto de datos y la cantidad de Ã©pocas que deseas entrenar.
```python
train(train_dataset, EPOCHS)
```
2. **Ver las imÃ¡genes generadas**: DespuÃ©s de entrenar el modelo, puedes visualizar las imÃ¡genes generadas por el generador en la Ãºltima Ã©poca. Esto se hace mediante la funciÃ³n `display_image()`.
```python
display_image(EPOCHS - 1)
```
3. **Guardar el modelo** ğŸ’¾: Al final del entrenamiento, el generador y el discriminador se guardan en archivos `.keras` para su posterior uso o fine-tuning.

## Resultados ğŸ“¸
El entrenamiento puede tomar varias horas dependiendo de la capacidad de la GPU o TPU utilizada. Los resultados generados en cada Ã©poca son guardados en archivos de imagen, que se pueden visualizar durante y despuÃ©s del entrenamiento.

### Ejemplo de ImÃ¡genes Generadas ğŸ–¼ï¸

A continuaciÃ³n, se muestran dos ejemplos de imÃ¡genes generadas durante el entrenamiento del modelo GAN:

1. **Imagen generada en la Ã©poca 02**:  
   ![Imagen generada Ã©poca 02](https://github.com/DavidMoCe/GAN-MNIST-FASHION/blob/main/image/start.png)

2. **Imagen generada en la Ãºltima Ã©poca**:  
   ![Imagen generada Ãºltima Ã©poca](https://github.com/DavidMoCe/GAN-MNIST-FASHION/blob/main/image/end.png)


## Licencia ğŸ“œ
Este proyecto estÃ¡ licenciado bajo la licencia **CC BY-NC 4.0**. Consulta el archivo [`LICENSE`](https://github.com/DavidMoCe/GAN-MNIST-FASHION/blob/main/LICENSE.txt) para mÃ¡s detalles.


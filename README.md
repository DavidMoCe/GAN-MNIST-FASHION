# Generator and Discriminator for Fashion MNIST with GAN 👗👚👟

## 🌍 Chose Your Language / Elige tu idioma:
- [English](#english-gb)
- [Español](#español-es)

---

## English GB

This project implements a Generative Adversarial Network (GAN) model to generate images of clothing and accessories using the *Fashion MNIST* dataset. The goal is to train a generator capable of creating realistic images from random noise, while the discriminator learns to distinguish between real and generated images. 🤖

## Requirements 📦
To run this project, you need to have the following libraries installed:
- **Python 3.x**
- **TensorFlow 2.x**
- **NumPy**
- **Matplotlib**
- **PIL (Python Imaging Library)**
- **imageio**

You can install these dependencies with `pip install tensorflow numpy matplotlib pillow imageio`.

## Model Description 📋
The project consists of two main components:
1. **Generator** 🎨: This model takes a random noise vector and transforms it into a 28x28 pixel image with a single channel (grayscale). Through a transposed convolution process, the generator creates images that mimic the clothing and accessories in the *Fashion MNIST* dataset.
2. **Discriminator** 🧐: The discriminator is a convolutional neural network that classifies images as real (from the dataset) or fake (generated by the generator). Its task is to learn to identify whether an image is genuine or generated, providing feedback to improve the generator.

## GAN Model Structure
- **Generator**: Uses dense layers and transposed convolution to generate images from random noise.
- **Discriminator**: Uses convolution to analyze images and a dense layer to classify the images as real or fake.

## Optimization ⚙️
Both models (generator and discriminator) are optimized using the **Adam** optimizer, which is widely used for its efficiency and adaptability to model gradients. **Binary cross-entropy** is the loss function used in this project, as it measures the difference between the discriminator's predictions and the real or fake labels. This allows both the generator and discriminator to learn from their mistakes and improve their respective tasks:
- **Generator**: Its goal is to fool the discriminator into classifying generated images as real.
- **Discriminator**: Its task is to correctly classify real and generated images, distinguishing true images from fake ones.

## Training 🚀
### Training Parameters 🔧
- **EPOCHS**: Number of epochs to train the model.
- **LATENT_DIM**: Dimension of the noise vector used as input to the generator.
- **BATCH_SIZE**: Number of images processed per batch during training.

During training, the generator and discriminator compete in a zero-sum game. The discriminator tries to correctly classify real and generated images, while the generator tries to deceive the discriminator by creating images that look real. The losses of both models are calculated using *Binary Cross-Entropy*.

### Training Progress 📈
At the end of each epoch, a set of images produced by the generator is generated and displayed to visualize the progress. The model saves the generated images at each epoch and allows you to see how they improve over time.


## Using the model
1. **Train the model**: To begin training, simply execute the `train()` function with the dataset and the number of epochs you want to train.
```python
train(train_dataset, EPOCHS)
```
2. **View generated images**: After training the model, you can view the images generated by the generator in the last epoch. This is done using the  `display_image()` function.
```python
display_image(EPOCHS - 1)
```
3. **Save the model** 💾: At the end of training, the generator and discriminator are saved as `.keras` files for later use or fine-tuning.

## Results 📸
Training may take several hours depending on the capacity of the GPU or TPU used. The results generated at each epoch are saved as image files, which can be viewed during and after training.

### Example of Generated Images 🖼️

Below are two examples of images generated during the training of the GAN model:

1. **Image generated in Epoch 02**:  
   ![Image generated in Epoch 02](https://github.com/DavidMoCe/GAN-MNIST-FASHION/blob/main/image/start.png)

2. **Image generated in the last epoch:**:  
   ![Image generated in the last epoch](https://github.com/DavidMoCe/GAN-MNIST-FASHION/blob/main/image/end.png)


## License 📜
This project is licensed under the **CC BY-NC 4.0** license. See the [`LICENSE`](https://github.com/DavidMoCe/GAN-MNIST-FASHION/blob/main/LICENSE.txt) file for more details.

---

## Español ES

Este proyecto implementa un modelo Generativo Antagónico (GAN) para generar imágenes de prendas de ropa y accesorios utilizando el conjunto de datos *Fashion MNIST*. El objetivo es entrenar un generador capaz de crear imágenes realistas a partir de ruido aleatorio, mientras que el discriminador aprende a distinguir entre imágenes reales y generadas. 🤖

## Requisitos 📦
Para ejecutar este proyecto, necesitas tener las siguientes librerías instaladas:
- **Python 3.x**
- **TensorFlow 2.x**
- **NumPy**
- **Matplotlib**
- **PIL (Python Imaging Library)**
- **imageio**

Se pueden instalar estas dependencias con `pip install tensorflow numpy matplotlib pillow imageio`

## Descripción del Modelo 📋
El proyecto consiste en dos componentes principales:
1. **Generador** 🎨: Este modelo toma un vector de ruido aleatorio y lo transforma en una imagen de 28x28 píxeles con una sola capa de canal (en escala de grises). A través de un proceso de convolución transpuesta, el generador crea imágenes que imitan las prendas de ropa y accesorios en el conjunto de datos *Fashion MNIST*.
2. **Discriminador** 🧐: El discriminador es una red neuronal convolucional que clasifica las imágenes entre reales (provenientes del conjunto de datos) y falsas (producidas por el generador). Su tarea es aprender a identificar si una imagen es genuina o generada, proporcionando retroalimentación para mejorar el generador.

## Estructura del Modelo GAN
- **Generador**: Utiliza capas densas y convolución transpuesta para generar imágenes a partir de ruido aleatorio.
- **Discriminador**: Usa convolución para analizar las imágenes y una capa densa para clasificar las imágenes como reales o falsas.

## Optimización ⚙️
Ambos modelos (generador y discriminador) se optimizan con el optimizador **Adam**, que es ampliamente utilizado por su eficiencia y capacidad para adaptarse a los gradientes de los modelos. La **entropía cruzada binaria** es la función de pérdida utilizada en este proyecto, ya que mide la diferencia entre las predicciones del discriminador y las etiquetas reales o falsas. Esto permite que tanto el generador como el discriminador aprendan de sus errores y mejoren en sus respectivas tareas:
- **Generador**: Su objetivo es engañar al discriminador para que clasifique las imágenes generadas como reales.
- **Discriminador**: Su tarea es clasificar correctamente las imágenes reales y generadas, distinguiendo las imágenes verdaderas de las falsas.

## Entrenamiento 🚀
### Parámetros de Entrenamiento 🔧
- **EPOCHS**: Número de épocas para entrenar el modelo.
- **LATENT_DIM**: Dimensión del vector de ruido utilizado como entrada del generador.
- **BATCH_SIZE**: Número de imágenes procesadas por lote durante el entrenamiento.

Durante el entrenamiento, el generador y el discriminador compiten en un juego de cero-suma. El discriminador intenta clasificar correctamente las imágenes reales y generadas, mientras que el generador intenta engañar al discriminador creando imágenes que parezcan reales. Las pérdidas de ambos modelos se calculan usando *Binary Cross-Entropy*.

### Progreso del Entrenamiento 📈
Al final de cada época, se genera un conjunto de imágenes producidas por el generador, que se muestran para visualizar el progreso. El modelo guarda las imágenes generadas en cada época y permite visualizar cómo mejoran con el tiempo.


## Uso del modelo
1. **Entrenar el modelo**: Para comenzar el entrenamiento, solo necesitas ejecutar la función `train()` con el conjunto de datos y la cantidad de épocas que deseas entrenar.
```python
train(train_dataset, EPOCHS)
```
2. **Ver las imágenes generadas**: Después de entrenar el modelo, puedes visualizar las imágenes generadas por el generador en la última época. Esto se hace mediante la función `display_image()`.
```python
display_image(EPOCHS - 1)
```
3. **Guardar el modelo** 💾: Al final del entrenamiento, el generador y el discriminador se guardan en archivos `.keras` para su posterior uso o fine-tuning.

## Resultados 📸
El entrenamiento puede tomar varias horas dependiendo de la capacidad de la GPU o TPU utilizada. Los resultados generados en cada época son guardados en archivos de imagen, que se pueden visualizar durante y después del entrenamiento.

### Ejemplo de Imágenes Generadas 🖼️

A continuación, se muestran dos ejemplos de imágenes generadas durante el entrenamiento del modelo GAN:

1. **Imagen generada en la época 02**:  
   ![Imagen generada época 02](https://github.com/DavidMoCe/GAN-MNIST-FASHION/blob/main/image/start.png)

2. **Imagen generada en la última época**:  
   ![Imagen generada última época](https://github.com/DavidMoCe/GAN-MNIST-FASHION/blob/main/image/end.png)


## Licencia 📜
Este proyecto está licenciado bajo la licencia **CC BY-NC 4.0**. Consulta el archivo [`LICENSE`](https://github.com/DavidMoCe/GAN-MNIST-FASHION/blob/main/LICENSE.txt) para más detalles.

